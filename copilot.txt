
package main

import (
    "context"
    "log"
    "os"
    "os/signal"
    "syscall"

    "github.com/Shopify/sarama"
)

type consumerGroupHandler struct{}

// Setup is run at the beginning of a new session, before ConsumeClaim
func (consumerGroupHandler) Setup(s sarama.ConsumerGroupSession) error { return nil }

// Cleanup is run at the end of a session, once all ConsumeClaim goroutines have exited
func (consumerGroupHandler) Cleanup(s sarama.ConsumerGroupSession) error { return nil }

// ConsumeClaim starts a consumer loop of the given claim (partition)
// Must run the loop and return only when claim.Messages() channel is closed
func (consumerGroupHandler) ConsumeClaim(sess sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error {
    for msg := range claim.Messages() {
        log.Printf("Message: topic=%s partition=%d offset=%d key=%s value=%s",
            msg.Topic, msg.Partition, msg.Offset, string(msg.Key), string(msg.Value))

        // Mark message consumed for commit
        sess.MarkMessage(msg, "")
    }
    return nil
}

func main() {
    brokers := []string{"localhost:9092"}
    groupID := "my-consumer-group"
    topics := []string{"test-topic"}

    config := sarama.NewConfig()
    config.Version = sarama.V2_6_0_0           // adjust to match your Kafka cluster version
    config.Consumer.Group.Rebalance.Strategy = sarama.BalanceStrategyRange
    config.Consumer.Offsets.Initial = sarama.OffsetNewest // or sarama.OffsetOldest
    config.Consumer.Return.Errors = true

    // For stable consumer offsets commits:
    config.Consumer.Group.Session.Timeout = 10 * 1000 // ms
    config.Consumer.Group.Heartbeat.Interval = 3 * 1000 // ms

    // Create consumer group
    cg, err := sarama.NewConsumerGroup(brokers, groupID, config)
    if err != nil {
        log.Fatalf("Error creating consumer group: %v", err)
    }
    defer cg.Close()

    ctx, cancel := context.WithCancel(context.Background())
    defer cancel()

    // Handle signals for graceful shutdown
    go func() {
        sigchan := make(chan os.Signal, 1)
        signal.Notify(sigchan, syscall.SIGINT, syscall.SIGTERM)
        <-sigchan
        log.Println("Shutdown signal received")
        cancel()
    }()

    handler := consumerGroupHandler{}

    // Consume in a loop to handle rebalances and errors
    for {
        if err := cg.Consume(ctx, topics, handler); err != nil {
            log.Printf("Error from consumer: %v", err)
        }
        // If context was cancelled, exit loop
        if ctx.Err() != nil {
            break
        }
    }

    log.Println("Consumer group closed")
}

// SASL/SSL (if your cluster is secured):
config.Net.SASL.Enable = true
config.Net.SASL.Mechanism = sarama.SASLTypePlaintext // or OAUTHBEARER, SCRAM
config.Net.SASL.User = "username"
config.Net.SASL.Password = "password"


####################################
config.Net.TLS.Enable = true
// Optionally set config.Net.TLS.Config = &tls.Config{...} for custom CA/cert


Sarama Equivalent
To match security.protocol=SASL_SSL and sasl.mechanisms=PLAIN, you must set:
✔ Enable TLS
✔ Enable SASL
✔ Use SASL/PLAIN mechanism

// === Equivalent of security.protocol = SASL_SSL ===
cfg.Net.TLS.Enable = true
cfg.Net.TLS.Config = &tls.Config{
    InsecureSkipVerify: false, // true only if testing with self‑signed certs
}

// === Equivalent of sasl.mechanisms = PLAIN ===
cfg.Net.SASL.Enable = true
cfg.Net.SASL.User = "your-username"
cfg.Net.SASL.Password = "your-password"
cfg.Net.SASL.Mechanism = sarama.SASLTypePlaintext // "PLAIN"


   // PLAINTEXT = no TLS, no SASL    
   cfg.Net.TLS.Enable = false    
   cfg.Net.SASL.Enable = false


###################################
###Kafka supports four official security protocol values:
Protocol        Meaning
PLAINTEXT       No encryption, no authentication (port 9092 typically)  
SSL             TLS encryption only (mTLS optional)
SASL_PLAINTEXT  SASL authentication without TLS
SASL_SSL        SASL authentication with TLS (recommended / most secure)

###   dev1-0 settings
sasl.mechanisms: "PLAIN"
security.protocol: "SASL_SSL"

### Producer
func main() {
    brokers := []string{"localhost:9092"}
    topic := "demo-topic"

    cfg := sarama.NewConfig()
    cfg.Producer.RequiredAcks = sarama.WaitForLocal     // leader ack only (faster)
    cfg.Producer.Retry.Max = 5
    cfg.Producer.Return.Successes = true                // enable successes channel
    cfg.Producer.Idempotent = true                      // safer exactly-once within a session
    cfg.Net.MaxOpenRequests = 1                         // required with Idempotent=true
    cfg.Producer.Compression = sarama.CompressionZSTD   // great ratio/throughput
    cfg.Producer.Flush.Bytes = 256 * 1024               // batch by size (tune)
    cfg.Producer.Flush.Frequency = 10e6                 // 10ms (tune)
    cfg.Version = sarama.V3_6_0

    prod, err := sarama.NewAsyncProducer(brokers, cfg)
    if err != nil {
        log.Fatalf("create async producer: %v", err)
    }
    defer prod.Close()

    // Goroutine to log successes
    go func() {
        for m := range prod.Successes() {
            log.Printf("ok topic=%s partition=%d offset=%d", m.Topic, m.Partition, m.Offset)
        }
    }()

    // Goroutine to log errors
    go func() {
        for e := range prod.Errors() {
            log.Printf("err topic=%s: %v", e.Msg.Topic, e.Err)
            // Optional: implement a retry/backoff queue if needed
        }
    }()

    // Send some messages
    for i := 0; i < 1000; i++ {
        msg := &sarama.ProducerMessage{
            Topic: topic,
            Key:   sarama.StringEncoder("user-123"),
            Value: sarama.StringEncoder("event payload"),
        }
        prod.Input() <- msg
    }

    // Graceful shutdown
    sig := make(chan os.Signal, 1)
    signal.Notify(sig, os.Interrupt, syscall.SIGTERM)
    <-sig
    log.Println("shutting down...")
}





